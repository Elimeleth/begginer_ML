{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/4Freek/begginer_ML/blob/main/Penguins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras Tuner using Comet.ML"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "4441540237064e23b52daf63e6deceaf",
        "is_collapsed": false,
        "owner_user_id": "61f7ecd5-97f2-4611-afd3-c247de2940e1",
        "formattedRanges": [],
        "deepnote_app_coordinates": {
          "h": 2,
          "w": 24,
          "x": 0,
          "y": null,
          "maxH": 2,
          "minH": 2
        },
        "deepnote_cell_type": "text-cell-h1",
        "id": "I1snAmO3Xg0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook aims to show a simple example of how to use the Keras Tuner to find the best set of hyperparameters to train a neural network model.\n",
        "\n",
        "In addition, this notebook synchronizes the experiments with a Comet.ML project.\n",
        "\n",
        "This notebook uses the [penguins dataset](https://www.kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data) and installs the `keras-tuner` library.\n",
        "\n",
        "<img src='https://imgur.com/orZWHly.png' alt='Penguins dataset'>"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "d981bb2d54bc4f27936c58dbfba3e3be",
        "deepnote_cell_height": 622.875,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 3,
          "minH": 5
        },
        "deepnote_cell_type": "markdown",
        "id": "s4tE743RXg0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install comet_ml keras_tuner"
      ],
      "metadata": {
        "id": "7jNJu0EGX2_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries and Initializing Comet\n",
        "\n",
        "Here we initialize Comet and create the Experiment we will use to log everything that happens. Here you'll need your Comet API_KEY."
      ],
      "metadata": {
        "id": "7wKQGR371ZLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "\n",
        "from comet_ml import Experiment\n",
        "from keras_tuner import RandomSearch\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, losses, metrics, optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
        "\n",
        "import comet_ml\n",
        "comet_ml.init()\n",
        "\n",
        "experiment = Experiment(\n",
        "    project_name=\"Penguins\",\n",
        "    auto_metric_logging=True,\n",
        "    auto_param_logging=True,\n",
        "    auto_histogram_weight_logging=True,\n",
        "    auto_histogram_gradient_logging=True,\n",
        "    auto_histogram_activation_logging=True,\n",
        ")"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "9b8faa57ba714f049e1d45eff4d14363",
        "source_hash": "7b06b9ed",
        "execution_start": 1656681123121,
        "execution_millis": 8117,
        "deepnote_cell_height": 387,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 9,
          "minH": 5
        },
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_M-w3GfXg0a",
        "outputId": "4848758b-943b-41eb-f059-b92991ce0abb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your Comet API key from https://www.comet.com/api/my/settings/\n",
            "(api key may not show as you type)\n",
            "Comet API key: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "COMET INFO: Comet API key is valid\n",
            "COMET WARNING: running in Google Colab, but can't find mounted drive. Using HOME instead\n",
            "COMET WARNING: if drive is mounted, set COMET_CONFIG to save config there\n",
            "COMET INFO: Comet API key saved in /root/.comet.config\n",
            "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: tensorboard, keras, tensorflow. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
            "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "COMET ERROR: Failed to calculate active processors count. Fall back to default CPU count 1\n",
            "COMET INFO: Couldn't find a Git repository in '/content' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
            "COMET INFO: Experiment is live on comet.com https://www.comet.com/svpino/penguins/e1f3287b121d4924b1d9894df9585228\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the data\n",
        "\n",
        "Let's start by downloading the raw dataset locally. Some of the examples in the TensorFlow documentation use this same dataset so I'm using the same file they use."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "89b17cda4fe54a4495febaf883daa18d",
        "is_collapsed": false,
        "formattedRanges": [],
        "deepnote_app_coordinates": {
          "h": 2,
          "w": 24,
          "x": 0,
          "y": 15,
          "maxH": 2,
          "minH": 2
        },
        "deepnote_cell_type": "text-cell-h2",
        "id": "gBTuiRLPXg0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIRECTORY = tempfile.mkdtemp(prefix=\"keras-tuner-data\")\n",
        "DATA_FILEPATH = os.path.join(DATA_DIRECTORY, \"penguins.csv\")\n",
        "\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins_size.csv\", \n",
        "    DATA_FILEPATH\n",
        ")\n",
        "\n",
        "df = pd.read_csv(DATA_FILEPATH)\n",
        "\n",
        "experiment.log_table(filename=\"penguins.csv\", tabular_data=df)\n",
        "df.info()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "a2b9bdb830e041ea84c4b26ff15ead76",
        "source_hash": "a4baa45a",
        "execution_start": 1656681134701,
        "execution_millis": 68,
        "deepnote_cell_height": 225,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 24,
          "minH": 5
        },
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4y-IDf5Xg0c",
        "outputId": "f9e6f8d8-019a-4c10-eb81-c0309f27671d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 344 entries, 0 to 343\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   species            344 non-null    object \n",
            " 1   island             344 non-null    object \n",
            " 2   culmen_length_mm   342 non-null    float64\n",
            " 3   culmen_depth_mm    342 non-null    float64\n",
            " 4   flipper_length_mm  342 non-null    float64\n",
            " 5   body_mass_g        342 non-null    float64\n",
            " 6   sex                334 non-null    object \n",
            "dtypes: float64(4), object(3)\n",
            "memory usage: 18.9+ KB\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline\n",
        "\n",
        "We can now prepare a pipeline with all the transformations that we want to apply to the different fields of the dataset.\n",
        "\n",
        "[Here](https://twitter.com/svpino/status/1429730545618112517?s=20) you can find more information about pipelines."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "3eef75c6862b450fae8f6fa8ca556f17",
        "deepnote_cell_height": 111.1875,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 30,
          "minH": 5
        },
        "deepnote_cell_type": "markdown",
        "id": "bG6wEViJXg0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_columns = [column for column in df.columns if df[column].dtype in [\"int64\", \"float64\"]]\n",
        "\n",
        "numerical_preprocessor = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_preprocessor = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"numerical\", numerical_preprocessor, numerical_columns),\n",
        "        (\"categorical\", categorical_preprocessor, [\"island\"]),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "19559cb004d449ceb0ad60ec33527f8c",
        "source_hash": "6274c750",
        "execution_start": 1656681139770,
        "execution_millis": 4,
        "deepnote_cell_height": 387,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 129,
          "minH": 5
        },
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "rQI4Nl1ZXg0c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split and Transform\n",
        "\n",
        "We can now split and transform the data.\n",
        "\n",
        "Notice how we should split the data before preprocessing it. If we run the preprocessing pipeline before splitting the data, we will be [leaking the test data into the training process](https://twitter.com/svpino/status/1425019257449025536?s=20). "
      ],
      "metadata": {
        "tags": [],
        "cell_id": "bdbff51716264046a3fb2784bc60ecaa",
        "deepnote_cell_height": 111.1875,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 141,
          "minH": 5
        },
        "deepnote_cell_type": "markdown",
        "id": "IUcMUaejXg0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.species\n",
        "X = df.drop([\"species\", \"sex\"], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, \n",
        "    y, \n",
        "    test_size=0.20, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "6f6d16c48f4e4136a3f3a38901b74de0",
        "source_hash": "686a1754",
        "execution_start": 1656681275873,
        "execution_millis": 26,
        "deepnote_cell_height": 369,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 135,
          "minH": 5
        },
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "cgunNooNXg0c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "We need a function that builds our model. For this example, we are going to build a simple dense network.\n",
        "\n",
        "There are three different hyperparameters that we want to tune:\n",
        "\n",
        "* The number of units of the first dense layer. We want to try `4`, `8`, and `12`.\n",
        "* The number of units of the second dense layer. We are also trying `4`, `8`, and `12`.\n",
        "* The learning rate. Here we want to try `1e-2` and `1e-3`.\n",
        "\n",
        "Notice how we are instrumenting our model with a couple of `hp.Int()` an `hp.Choice()` function. This is how the Tuner knows which parameters to tune.\n",
        "\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "ba9398c58fdb4d1fbceaec49b7a98aa9",
        "is_collapsed": false,
        "formattedRanges": [],
        "deepnote_app_coordinates": {
          "h": 2,
          "w": 24,
          "x": 0,
          "y": 36,
          "maxH": 2,
          "minH": 2
        },
        "deepnote_cell_type": "text-cell-h2",
        "id": "IZysygsjXg0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _model(hp):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(\n",
        "            hp.Int(\"dense_1_units\", min_value=4, max_value=12, step=4, default=8),\n",
        "            input_shape=(X_train.shape[1],)\n",
        "            \n",
        "        ),\n",
        "        layers.Dense(\n",
        "            hp.Int(\"dense_2_units\", min_value=4, max_value=12, step=4, default=8), \n",
        "            activation=\"relu\"\n",
        "        ),\n",
        "        layers.Dense(3, activation=\"softmax\"),\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(\n",
        "            hp.Choice(\"learning_rate\", values=[1e-2, 1e-3])\n",
        "        ),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "9bc72239dcfe4564887eee7b6e0338c0",
        "source_hash": "48f860ce",
        "execution_start": 1656681277172,
        "execution_millis": 3,
        "deepnote_cell_height": 477,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 45,
          "minH": 5
        },
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "id": "cfkhgDsLXg0d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter tuning\n",
        "\n",
        "We are now ready to start searching for the best hyperparameter values.\n",
        "\n",
        "First, let's instantiate the tuner. Here we are using the [`RandomSearch`](https://keras.io/api/keras_tuner/tuners/random/) strategy. (At this time, the Keras Tuner also supports [`BayesianOptimization`](https://keras.io/api/keras_tuner/tuners/bayesian/), [`Hyperband`](https://keras.io/api/keras_tuner/tuners/hyperband/), and [`Sklearn`](https://keras.io/api/keras_tuner/tuners/sklearn/).)\n",
        "\n",
        "The way the tunner will determine the best model is by looking at the validation accuracy and we are going to be running 10 trials.\n",
        "\n",
        "Then, we can kick off the search. The signature of the `search()` function is the same as the `model.fit()` function in Keras.\n",
        "\n",
        "Finally, we can print the results of the tuning process. They will be sorted with the best hyperparameter values at the top."
      ],
      "metadata": {
        "tags": [],
        "cell_id": "c4734c04b2f54d3d92a5cca7f725234c",
        "deepnote_cell_height": 169.984375,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 54,
          "minH": 5
        },
        "deepnote_cell_type": "markdown",
        "id": "7cJTGXCVXg0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    _model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    overwrite=True,\n",
        "    directory=\"keras-tuner\",\n",
        "    project_name=\"keras-tuner-example\",\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(\n",
        "    X_train[:,:], \n",
        "    to_categorical(y_train), \n",
        "    epochs=5, \n",
        "    validation_data=(X_test[:,:], to_categorical(y_test))\n",
        ")\n",
        "\n",
        "tuner.results_summary()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "75ccd09d1f6f41a1a8c8b06ebee10b53",
        "source_hash": "19820f80",
        "execution_start": 1656681279463,
        "execution_millis": 180,
        "deepnote_cell_height": 207,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 60,
          "minH": 5
        },
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvUBxNrpXg0d",
        "outputId": "20893de1-0ac9-4342-c913-376c1862778b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 01s]\n",
            "val_accuracy: 0.9855072498321533\n",
            "\n",
            "Best val_accuracy So Far: 0.9855072498321533\n",
            "Total elapsed time: 00h 00m 15s\n",
            "Results summary\n",
            "Results in keras-tuner/keras-tuner-example\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7fd3c43bbca0>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dense_1_units: 12\n",
            "dense_2_units: 8\n",
            "learning_rate: 0.01\n",
            "Score: 0.9855072498321533\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dense_1_units: 4\n",
            "dense_2_units: 12\n",
            "learning_rate: 0.01\n",
            "Score: 0.9855072498321533\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dense_1_units: 12\n",
            "dense_2_units: 4\n",
            "learning_rate: 0.01\n",
            "Score: 0.95652174949646\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dense_1_units: 4\n",
            "dense_2_units: 8\n",
            "learning_rate: 0.01\n",
            "Score: 0.8405796885490417\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dense_1_units: 12\n",
            "dense_2_units: 4\n",
            "learning_rate: 0.001\n",
            "Score: 0.7681159377098083\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dense_1_units: 8\n",
            "dense_2_units: 4\n",
            "learning_rate: 0.01\n",
            "Score: 0.7681159377098083\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dense_1_units: 4\n",
            "dense_2_units: 4\n",
            "learning_rate: 0.001\n",
            "Score: 0.6811594367027283\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dense_1_units: 8\n",
            "dense_2_units: 4\n",
            "learning_rate: 0.001\n",
            "Score: 0.5507246255874634\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dense_1_units: 8\n",
            "dense_2_units: 12\n",
            "learning_rate: 0.001\n",
            "Score: 0.5507246255874634\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "dense_1_units: 12\n",
            "dense_2_units: 8\n",
            "learning_rate: 0.001\n",
            "Score: 0.5072463750839233\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making predictions\n",
        "\n",
        "We can use the best model that the tuner found to make predictions on the test set.\n",
        "\n",
        "We then create a table with the test data, the target, and the predictions and log it to the Experiment.\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "6a84f25b476247aa9e3c376f8bf9c8e2",
        "is_collapsed": false,
        "formattedRanges": [],
        "deepnote_app_coordinates": {
          "h": 2,
          "w": 24,
          "x": 0,
          "y": 102,
          "maxH": 2,
          "minH": 2
        },
        "deepnote_cell_type": "text-cell-h2",
        "id": "ro5M0zbnXg0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "y_pred = np.argmax(best_model.predict(X_test), axis=-1)\n",
        "accuracy = np.sum(y_pred == y_test) / len(y_test) * 100\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "results = pd.DataFrame(np.concatenate((\n",
        "    X_test, \n",
        "    np.expand_dims(y_test, axis=1), \n",
        "    np.expand_dims(y_pred, axis=1)), axis=1), columns=[\n",
        "        \"Culmen Length\", \"Culmen Depth\", \"Flipper Length\", \"Body Mass\", \n",
        "        \"Island - Biscoe\", \"Island - Dream\", \"Island - Torgersen\", \n",
        "        \"Species\", \"Prediction\"]\n",
        ")\n",
        "\n",
        "experiment.log_table(filename=\"results.csv\", tabular_data=results)\n",
        "experiment.display(\"panels\")\n",
        "experiment.end()"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "a0026ee5e2cc4ed6add986063919c021",
        "source_hash": "1cb5f7da",
        "execution_start": 1656681313805,
        "execution_millis": 290,
        "deepnote_cell_height": 81,
        "deepnote_app_coordinates": {
          "h": 5,
          "w": 24,
          "x": 0,
          "y": 111,
          "minH": 5
        },
        "deepnote_to_be_reexecuted": false,
        "deepnote_cell_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r-tNVw92Xg0e",
        "outputId": "d7e8d636-3c8a-4272-b6ac-67edf6fbe8ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fd3ada1f3a0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800px\"\n",
              "            src=\"https://www.comet.com/svpino/penguins/e1f3287b121d4924b1d9894df9585228\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "COMET INFO: ---------------------------------------------------------------------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------------------------------------------------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.com/svpino/penguins/e1f3287b121d4924b1d9894df9585228\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     add_indicator       : False\n",
            "COMET INFO:     categories          : auto\n",
            "COMET INFO:     copy                : True\n",
            "COMET INFO:     drop                : 1\n",
            "COMET INFO:     dtype               : <class 'numpy.float64'>\n",
            "COMET INFO:     fill_value          : 1\n",
            "COMET INFO:     handle_unknown      : ignore\n",
            "COMET INFO:     keep_empty_features : False\n",
            "COMET INFO:     max_categories      : 1\n",
            "COMET INFO:     min_frequency       : 1\n",
            "COMET INFO:     missing_values      : nan\n",
            "COMET INFO:     sparse              : deprecated\n",
            "COMET INFO:     sparse_output       : True\n",
            "COMET INFO:     strategy            : most_frequent\n",
            "COMET INFO:     verbose             : deprecated\n",
            "COMET INFO:     with_mean           : True\n",
            "COMET INFO:     with_std            : True\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     dataframe           : 2 (22.78 KB)\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     notebook            : 2\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO:     source_code         : 1\n",
            "COMET INFO: \n",
            "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: tensorboard, keras, tensorflow. Metrics and hyperparameters can still be logged using Experiment.log_metrics() and Experiment.log_parameters()\n",
            "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
            "COMET INFO: The Python SDK has 3600 seconds to finish uploading collected data\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLCRg6VMBSXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote": {
      "is_reactive": false
    },
    "orig_nbformat": 2,
    "deepnote_app_layout": "article",
    "deepnote_notebook_id": "565ac720f8134c8b9ec798b3a6f5f0b6",
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  }
}